{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqv8ZjxBEZs7GFXTRdvxMV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afsin1/llm/blob/main/word_level_biagram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45FNOyNOjN6L"
      },
      "outputs": [],
      "source": [
        "words = []\n",
        "b_dict = {}\n",
        "\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    words = f.read().splitlines()\n",
        "\n",
        "#input_text = \"how are you today everyone? Are you feeling good? Are you ok? Are you fine? how are you doing? Are there anyone we missed? are\"\n",
        "#words = input_text.lower().split()\n",
        "\n",
        "for i in range(len(words) - 1):\n",
        "    bigram = (words[i], words[i + 1])\n",
        "    b_dict[bigram] = b_dict.get(bigram, 0) + 1\n",
        "\n",
        "\n",
        "b_dict = sorted(b_dict.items(), key = lambda kv: -kv[1]) # sort by the count (value)\n",
        "#b_dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# assign numbers to words. In other words encode them.\n",
        "vocab = sorted(list(set(words)))\n",
        "print(len(vocab))\n",
        "\n",
        "wtoi = {}\n",
        "itow = {}\n",
        "\n",
        "wtoi = {w:i+1 for i,w in enumerate(vocab)}\n",
        "wtoi['.'] = 0\n",
        "itow = {i:w for w,i in wtoi.items()}\n",
        "\n",
        "#print(len(wtoi.items()))\n",
        "#print(sorted(wtoi.items(), key = lambda i: i[1]))\n",
        "#print(sorted(itow.items(), key = lambda i: i[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nuCTwHVn5_d",
        "outputId": "872ed487-8b1f-40ad-a14a-11d423d0b94e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11583\n",
            "11584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# numbers - > vectors (one hot encoding)\n",
        "import torch\n",
        "\n",
        "vocab_size = len(vocab) + 1 # +1 for the special cha '.'\n",
        "vocab_encodings = torch.zeros(vocab_size, vocab_size) # 1 x 9\n",
        "\n",
        "print (vocab_encodings.shape)\n",
        "for i in range(len(b_dict)):\n",
        "  biagram = b_dict[i][0]\n",
        "  count = b_dict[i][1]\n",
        "  if count > 0:\n",
        "    vocab_encodings[wtoi[biagram[0]], wtoi[biagram[1]]] = count\n",
        "\n",
        "#print(vocab_encodings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yGHniOj22Xq",
        "outputId": "adf4d854-3501-490e-e384-ca8b43bcdc95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([11584, 11584])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count -> prob distirbution\n",
        "P = vocab_encodings.float()\n",
        "P /= P.sum(1, keepdim=True)\n",
        "P = P[1:]\n",
        "P"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfiKhOsME96F",
        "outputId": "235c3dce-a78c-48e0-b84d-f8350e6bce8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0391, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.3333, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        ...,\n",
              "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure(figsize=(28,28))\n",
        "plt.imshow(vocab_encodings, cmap='Blues')\n",
        "for i in range(15):\n",
        "    for j in range(15):\n",
        "        chstr = itow[i] + \" \" + itow[j]\n",
        "        plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color='gray')\n",
        "        plt.text(j, i, vocab_encodings[i, j].item(), ha=\"center\", va=\"top\", color='gray')\n",
        "plt.axis('off');"
      ],
      "metadata": {
        "id": "WFWaV_m5HgQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(123456)\n",
        "\n",
        "for i in range(3):\n",
        "\n",
        "    out = []\n",
        "    ix = 0\n",
        "    while True:\n",
        "        p = P[ix]\n",
        "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "        out.append(itow[ix] + \" \")\n",
        "\n",
        "\n",
        "        if itow[ix].endswith(\"?\"):\n",
        "          break\n",
        "\n",
        "    print(''.join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LYHePe7RPC0",
        "outputId": "4a597f6c-f50f-49b6-b0b4-d080e2e34616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The echo of that passionate appeal— thought—But I have been too kind—too indulgent! One finds one's  1.E.2. If an individual Project Gutenberg™ electronic work is with the permission of the copyright holder, your use and distribution while the lips were alike more sad and more satirical than four years a particular characteristic to a particular bump, and leave it there label him; and Miss Devereux endeavoured perplexedly to wade after misery for either of them? \n",
            "   \"You can't do some things with impunity.\"    I'm simply sorry for the griefs you've had.\"  1.E.2. If an individual Project Gutenberg™ electronic work is with the permission of the copyright holder, your use and distribution while the lips were alike more sad and more satirical than four years a particular characteristic to a particular bump, and leave it there label him; and Miss Devereux endeavoured perplexedly to wade after misery for either of them? \n",
            "Evelyn sighed. \"I wish I had not let him go. Suppose he takes a bad was glad to know it. Jean interested her: not only for the sake of Mr. remarks on Cyril. As already stated, he was not chivalrous, and Jean East-End all this time!\" restlessness. Sometimes she talks as it were—but that is because she  1.E.2. If an individual Project Gutenberg™ electronic work is with the permission of the copyright holder, your use and distribution while the lips were alike more sad and more satirical than four years a particular characteristic to a particular bump, and leave it there label him; and Miss Devereux endeavoured perplexedly to wade after misery for either of them? \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5DxnyTfeVyGV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}