{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d71c87-60a9-47da-bf4f-7b6931c97fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "b_dict = {}\n",
    "\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    words = f.read().splitlines()\n",
    "\n",
    "#input_text = \"how are you today everyone? Are you feeling good? Are you ok? Are you fine? how are you doing? Are there anyone we missed? are\"\n",
    "#words = input_text.lower().split()\n",
    "\n",
    "for i in range(len(words) - 1):\n",
    "    bigram = (words[i], words[i + 1])\n",
    "    b_dict[bigram] = b_dict.get(bigram, 0) + 1\n",
    "\n",
    "\n",
    "b_dict = sorted(b_dict.items(), key = lambda kv: -kv[1]) # sort by the count (value)\n",
    "#b_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd523e5b-d338-4b52-86d4-78ce8a32c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign numbers to words. In other words encode them.\n",
    "vocab = sorted(list(set(words)))\n",
    "print(len(vocab))\n",
    "\n",
    "wtoi = {}\n",
    "itow = {}\n",
    "\n",
    "wtoi = {w:i+1 for i,w in enumerate(vocab)}\n",
    "wtoi['.'] = 0\n",
    "itow = {i:w for w,i in wtoi.items()}\n",
    "\n",
    "#print(len(wtoi.items()))\n",
    "#print(sorted(wtoi.items(), key = lambda i: i[1]))\n",
    "#print(sorted(itow.items(), key = lambda i: i[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ef587f-2674-473d-b77c-ff7145d024c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numbers - > vectors (one hot encoding)\n",
    "import torch\n",
    "\n",
    "vocab_size = len(vocab) + 1 # +1 for the special cha '.'\n",
    "vocab_encodings = torch.zeros(vocab_size, vocab_size) # 1 x 9\n",
    "\n",
    "print (vocab_encodings.shape)\n",
    "for i in range(len(b_dict)):\n",
    "  biagram = b_dict[i][0]\n",
    "  count = b_dict[i][1]\n",
    "  if count > 0:\n",
    "    vocab_encodings[wtoi[biagram[0]], wtoi[biagram[1]]] = count\n",
    "\n",
    "#print(vocab_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c672936-ac42-4f9e-b284-547585946397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count -> prob distirbution\n",
    "P = vocab_encodings.float()\n",
    "P /= P.sum(1, keepdim=True)\n",
    "P = P[1:]\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b9f51a-d3d3-4d47-b9fa-b46328aa06fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(28,28))\n",
    "plt.imshow(vocab_encodings, cmap='Blues')\n",
    "for i in range(15):\n",
    "    for j in range(15):\n",
    "        chstr = itow[i] + \" \" + itow[j]\n",
    "        plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color='gray')\n",
    "        plt.text(j, i, vocab_encodings[i, j].item(), ha=\"center\", va=\"top\", color='gray')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1711da3-1913-4ee5-8b07-2e012c5dcb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(123456)\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "        p = P[ix]\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itow[ix] + \" \")\n",
    "\n",
    "\n",
    "        if itow[ix].endswith(\"?\"):\n",
    "          break\n",
    "\n",
    "    print(''.join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
