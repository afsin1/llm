{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45FNOyNOjN6L"
      },
      "outputs": [],
      "source": [
        "words = []\n",
        "b_dict = {}\n",
        "\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    words = f.read().splitlines()\n",
        "\n",
        "#input_text = \"how are you today everyone? Are you feeling good? Are you ok? Are you fine? how are you doing? Are there anyone we missed? are\"\n",
        "#words = input_text.lower().split()\n",
        "\n",
        "for i in range(len(words) - 1):\n",
        "    bigram = (words[i], words[i + 1])\n",
        "    b_dict[bigram] = b_dict.get(bigram, 0) + 1\n",
        "\n",
        "\n",
        "b_dict = sorted(b_dict.items(), key = lambda kv: -kv[1]) # sort by the count (value)\n",
        "#b_dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# assign numbers to words. In other words encode them.\n",
        "vocab = sorted(list(set(words)))\n",
        "print(len(vocab))\n",
        "\n",
        "wtoi = {}\n",
        "itow = {}\n",
        "\n",
        "wtoi = {w:i+1 for i,w in enumerate(vocab)}\n",
        "wtoi['.'] = 0\n",
        "itow = {i:w for w,i in wtoi.items()}\n",
        "\n",
        "print(sorted(wtoi.items(), key = lambda i: i[1]))\n",
        "print(sorted(itow.items(), key = lambda i: i[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nuCTwHVn5_d",
        "outputId": "78479c05-b0c3-4326-c2a9-701b6fc32010"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n",
            "[('.', 0), ('anyone', 1), ('are', 2), ('doing?', 3), ('everyone?', 4), ('feeling', 5), ('fine?', 6), ('good?', 7), ('how', 8), ('missed?', 9), ('ok?', 10), ('there', 11), ('today', 12), ('we', 13), ('you', 14)]\n",
            "[(0, '.'), (1, 'anyone'), (2, 'are'), (3, 'doing?'), (4, 'everyone?'), (5, 'feeling'), (6, 'fine?'), (7, 'good?'), (8, 'how'), (9, 'missed?'), (10, 'ok?'), (11, 'there'), (12, 'today'), (13, 'we'), (14, 'you')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# numbers - > vectors (one hot encoding)\n",
        "import torch\n",
        "\n",
        "vocab_size = len(vocab) + 1 # +1 for the special cha '.'\n",
        "vocab_encodings = torch.zeros(vocab_size, vocab_size) # 1 x 9\n",
        "\n",
        "print (vocab_encodings.shape)\n",
        "for i in range(len(b_dict)):\n",
        "  biagram = b_dict[i][0]\n",
        "  count = b_dict[i][1]\n",
        "  if count > 0:\n",
        "    vocab_encodings[wtoi[biagram[0]], wtoi[biagram[1]]] = count\n",
        "\n",
        "print(vocab_encodings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yGHniOj22Xq",
        "outputId": "8452c89b-ea35-4e5b-f19c-34fdb4f17981"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([15, 15])\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 5.],\n",
            "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count -> prob distirbution\n",
        "P = vocab_encodings.float()\n",
        "P /= P.sum(1, keepdim=True)\n",
        "P = P[1:]\n",
        "P"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfiKhOsME96F",
        "outputId": "fe532e8d-609e-4d94-9cc2-40250f3b48f1"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.1667, 0.0000, 0.0000, 0.8333],\n",
              "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.2000, 0.0000, 0.2000, 0.2000, 0.0000, 0.0000,\n",
              "         0.0000, 0.2000, 0.0000, 0.2000, 0.0000, 0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure(figsize=(28,28))\n",
        "plt.imshow(vocab_encodings, cmap='Blues')\n",
        "for i in range(15):\n",
        "    for j in range(15):\n",
        "        chstr = itow[i] + \" \" + itow[j]\n",
        "        plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color='gray')\n",
        "        plt.text(j, i, vocab_encodings[i, j].item(), ha=\"center\", va=\"top\", color='gray')\n",
        "plt.axis('off');"
      ],
      "metadata": {
        "id": "WFWaV_m5HgQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(123456)\n",
        "\n",
        "for i in range(3):\n",
        "\n",
        "    out = []\n",
        "    ix = 0\n",
        "    while True:\n",
        "        p = P[ix]\n",
        "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "        out.append(itow[ix] + \" \")\n",
        "\n",
        "\n",
        "        if itow[ix].endswith('?'):\n",
        "          break\n",
        "\n",
        "    print(''.join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LYHePe7RPC0",
        "outputId": "c27dcf03-fe87-4840-d68c-6dbb9c85da3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we today missed? \n"
          ]
        }
      ]
    }
  ]
}